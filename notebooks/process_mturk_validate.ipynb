{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a1732b-2c69-49b6-9ab4-6cde60bd52ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.2.2 available.\n"
     ]
    }
   ],
   "source": [
    "from collections import ChainMap\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from valueconsistency import *\n",
    "from measures import *\n",
    "from plots import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b22274b-7b6d-48f1-acf0-7578b2fb4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de24bd77-f479-45b0-a881-5a930cc4ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_paraphrase_validate_cloud_research(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    d = df[['Task Data', 'Submitted Data']].dropna().reset_index(drop=True).map(json.loads)\n",
    "    \n",
    "    d['Submitted Data'] = d['Submitted Data'].apply(lambda x: x['Data']['taskData'])\n",
    "    \n",
    "    def process_cloud_research_task_data(row):\n",
    "        list_of_dicts = [{col['ColumnHeader'] : col['CellData']} for col in row['RowData']]\n",
    "        result = dict(ChainMap(*list_of_dicts)) # {k: v for d in list_of_dicts for k, v in d.items()}\n",
    "        return result\n",
    "    \n",
    "    d['Task Data'] = d['Task Data'].apply(process_cloud_research_task_data)\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for _, row in d.iterrows():\n",
    "        rows = dict(ChainMap(*row.values))\n",
    "        num_qs = len({k for k in rows.keys() if re.fullmatch(r'q_\\d', k)})\n",
    "        if rows['topic'].startswith('['):\n",
    "            topics = eval(rows['topic'])\n",
    "        else:\n",
    "            topics = rows['topic']\n",
    "\n",
    "        for i in range(num_qs):\n",
    "            result = {'answer' : rows[f'q_{i}'],\n",
    "                        'topic' : topics if isinstance(topics, str) else topics[i],\n",
    "                        'tm' : rows['tm']}\n",
    "            if f'q_{i}_question' in rows and rows[f'q_{i}_question']:\n",
    "                result['original'] = rows[f'q_{i}_question']\n",
    "            results.append(result)\n",
    "\n",
    "    result =  pd.DataFrame(results)\n",
    "    result['tm'] = result['tm'].astype('float')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b89f86d-625e-4467-9e8c-b5f0523b172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "controversial_dir = 'data/validate/controversial'\n",
    "paraphrase_dir = 'data/validate/paraphrase/cloud_research'\n",
    "\n",
    "\n",
    "stats = []\n",
    "total_equivalent_n = 0\n",
    "total_equivalent = 0\n",
    "\n",
    "total_controversial_n = 0\n",
    "total_controversial = 0\n",
    "\n",
    "total_uncontroversial_n = 0\n",
    "total_uncontroversial = 0\n",
    "\n",
    "all_controversial = []\n",
    "all_uncontroversial = []\n",
    "\n",
    "\n",
    "for controversial in [True, False]:\n",
    "    for language, country in [('english', 'us'), ('german', 'germany'),\n",
    "                              ('chinese', 'china'), ('japanese', 'japan')]:\n",
    "\n",
    "        controversial_str = \"\\cmark\" if controversial else '\\\\xmark'\n",
    "        result = {\n",
    "            'Controversial' : controversial_str,\n",
    "            'Language' : language.capitalize(),\n",
    "            'Country' : country.capitalize() if country != 'us' else \"U.S.\",\n",
    "        }\n",
    "        name = f'{\"controversial\" if controversial else \"uncontroversial\"}_{language}_{country}'\n",
    "\n",
    "        ### Paraphrase stats\n",
    "        filename = f'{paraphrase_dir}/{name}.csv'\n",
    "        if os.path.exists(filename):\n",
    "            df = process_paraphrase_validate_cloud_research(filename)\n",
    "            df['questions_equivalent'] = df['answer']\n",
    "            df.to_csv(f'data/validate/paraphrase/{name}.csv')\n",
    "    \n",
    "            n = len(df)\n",
    "            n_equivalent = df['questions_equivalent'].value_counts()['yes']\n",
    "            total_equivalent_n += n\n",
    "            total_equivalent += n_equivalent\n",
    "    \n",
    "            result['# (%) Equivalent'] = f\"{n_equivalent} / {n} ({n_equivalent / n:.0%})\"\n",
    "\n",
    "        #### Controversial stats\n",
    "        cont_str = 'controversial' if controversial else 'uncontroversial'\n",
    "        name = f\"{cont_str}_{language}_{country}\"\n",
    "        dfs = []\n",
    "        for i in range(3):\n",
    "            df = process_paraphrase_validate_cloud_research(f'{controversial_dir}/cloud_research/{name}_{i + 1}.csv')\n",
    "            controversial_value = df['answer'].apply(lambda x: [\"Very controversial\",  \"Somewhat controversial\",\n",
    "                                           \"Not very controversial\", \"Not at all controversial\"].index(x))\n",
    "            if controversial:\n",
    "                all_controversial += controversial_value.to_list()\n",
    "            else:\n",
    "                all_uncontroversial += controversial_value.to_list()\n",
    "            df['controversial'] = df['answer'].apply(lambda x: x in ['Very controversial', 'Somewhat controversial'])\n",
    "            dfs.append(df)\n",
    "        \n",
    "        df = pd.concat(dfs).groupby('topic').agg(lambda x: list(x)).reset_index()\n",
    "        df['controversial'] = df['controversial'].apply(lambda x: np.mean(x) > .5)\n",
    "        df.to_csv(f'{controversial_dir}/{name}.csv')\n",
    "\n",
    "        n = len(df)\n",
    "        n_controversial = df['controversial'].sum()\n",
    "        if controversial:\n",
    "            total_controversial_n += n\n",
    "            total_controversial += n_controversial\n",
    "        else:\n",
    "            total_uncontroversial_n += n\n",
    "            total_uncontroversial += n_controversial\n",
    "        result['# (%) Controversial'] =  f\"{n_controversial} / {n} ({n_controversial / n:.0%})\"\n",
    "\n",
    "        ### Record the stats\n",
    "        \n",
    "        stats.append(result)\n",
    "\n",
    "cont_str = f\"{total_controversial} / {total_controversial_n} ({total_controversial / total_controversial_n:.0%})\"\n",
    "uncont_str = f\"{total_uncontroversial} / {total_uncontroversial_n} ({total_uncontroversial / total_uncontroversial_n:.0%})\"\n",
    "\n",
    "stats.append({'# (%) Equivalent' : f\"{total_equivalent} / {total_equivalent_n} ({total_equivalent / total_equivalent_n:.0%})\",\n",
    "              '# (%) Controversial' : f\"{cont_str}\\n{uncont_str}\"\n",
    "             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bc145a4-f66b-4885-89a6-0d4d9b26750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controversial_n = len(all_uncontroversial) + len(all_controversial)\n",
    "controversial_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf1744f2-4371-489a-bcba-f768da4a6610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      " & Controversial & Language & Country & # (%) Controversial & # (%) Equivalent \\\\\n",
      "\\midrule\n",
      "0 & \\cmark & English & U.S. & 22 / 28 (79%) & NaN \\\\\n",
      "1 & \\cmark & German & Germany & 19 / 28 (68%) & 100 / 137 (73%) \\\\\n",
      "2 & \\cmark & Chinese & China & 16 / 22 (73%) & 70 / 101 (69%) \\\\\n",
      "3 & \\cmark & Japanese & Japan & 19 / 21 (90%) & 54 / 84 (64%) \\\\\n",
      "4 & \\xmark & English & U.S. & 11 / 20 (55%) & NaN \\\\\n",
      "5 & \\xmark & German & Germany & 7 / 18 (39%) & 51 / 68 (75%) \\\\\n",
      "6 & \\xmark & Chinese & China & 7 / 23 (30%) & 59 / 87 (68%) \\\\\n",
      "7 & \\xmark & Japanese & Japan & 12 / 20 (60%) & 55 / 85 (65%) \\\\\n",
      "8 & NaN & NaN & NaN & 76 / 99 (77%)\n",
      "37 / 81 (46%) & 389 / 562 (69%) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(stats).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14fcfe78-df73-44a8-8042-bcc8042f9ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Controversial</th>\n",
       "      <th>Language</th>\n",
       "      <th>Country</th>\n",
       "      <th># (%) Controversial</th>\n",
       "      <th># (%) Equivalent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\cmark</td>\n",
       "      <td>English</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>22 / 28 (79%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\cmark</td>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>19 / 28 (68%)</td>\n",
       "      <td>100 / 137 (73%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\cmark</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>China</td>\n",
       "      <td>16 / 22 (73%)</td>\n",
       "      <td>70 / 101 (69%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\cmark</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japan</td>\n",
       "      <td>19 / 21 (90%)</td>\n",
       "      <td>54 / 84 (64%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\xmark</td>\n",
       "      <td>English</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>11 / 20 (55%)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\xmark</td>\n",
       "      <td>German</td>\n",
       "      <td>Germany</td>\n",
       "      <td>7 / 18 (39%)</td>\n",
       "      <td>51 / 68 (75%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\xmark</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>China</td>\n",
       "      <td>7 / 23 (30%)</td>\n",
       "      <td>59 / 87 (68%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\xmark</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>Japan</td>\n",
       "      <td>12 / 20 (60%)</td>\n",
       "      <td>55 / 85 (65%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76 / 99 (77%)\\n37 / 81 (46%)</td>\n",
       "      <td>389 / 562 (69%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Controversial  Language  Country           # (%) Controversial  \\\n",
       "0        \\cmark   English     U.S.                 22 / 28 (79%)   \n",
       "1        \\cmark    German  Germany                 19 / 28 (68%)   \n",
       "2        \\cmark   Chinese    China                 16 / 22 (73%)   \n",
       "3        \\cmark  Japanese    Japan                 19 / 21 (90%)   \n",
       "4        \\xmark   English     U.S.                 11 / 20 (55%)   \n",
       "5        \\xmark    German  Germany                  7 / 18 (39%)   \n",
       "6        \\xmark   Chinese    China                  7 / 23 (30%)   \n",
       "7        \\xmark  Japanese    Japan                 12 / 20 (60%)   \n",
       "8           NaN       NaN      NaN  76 / 99 (77%)\\n37 / 81 (46%)   \n",
       "\n",
       "  # (%) Equivalent  \n",
       "0              NaN  \n",
       "1  100 / 137 (73%)  \n",
       "2   70 / 101 (69%)  \n",
       "3    54 / 84 (64%)  \n",
       "4              NaN  \n",
       "5    51 / 68 (75%)  \n",
       "6    59 / 87 (68%)  \n",
       "7    55 / 85 (65%)  \n",
       "8  389 / 562 (69%)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b974680-c971-48c6-89e6-619415cb564b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=7.477942000824478, pvalue=3.0434879452707325e-13, df=544.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "scipy.stats.ttest_ind(all_uncontroversial, all_controversial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a626f6b-db0a-4702-8b6c-604e253d4506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinomTestResult(k=389, n=562, alternative='two-sided', statistic=0.6921708185053381, pvalue=4.1259838577612583e-20)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.binomtest(k=total_equivalent, n=total_equivalent_n, p=.5, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde3d207-8375-4456-9056-09d9ba0943ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-valueconsistency",
   "language": "python",
   "name": "env-valueconsistency"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
